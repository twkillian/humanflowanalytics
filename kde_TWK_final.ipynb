{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from math import *\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('data-final/train-final.txt', dtype=int, delimiter=',',skiprows=1)\n",
    "orig_data = np.copy(data)\n",
    "num_sensors = data.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_data(data, sensor, time_start, time_end):\n",
    "    # Get starting index and ending index, derived from time_start and time_end\n",
    "    st_day, en_day = time_start/10000, time_end/10000\n",
    "    st_hour, en_hour = (time_start%10000)/100, (time_end%10000)/100\n",
    "    st_min, en_min = time_start%100, time_end%100\n",
    "    st_index = (st_day-1)*1440 + st_hour*60 + st_min\n",
    "    en_index = (en_day-1)*1440 + en_hour*60 + en_min\n",
    "    \n",
    "    return np.sum(data[st_index:en_index+1,sensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get nearest neighbors of each piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data-final/sensor-coordinates.txt') as f:\n",
    "    coords = list()\n",
    "    reader = csv.reader(f)\n",
    "    reader.next()\n",
    "    for row in reader:\n",
    "        coords.append((float(row[1]), float(row[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(p1, p2):\n",
    "    return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nearest(coords, r=10):\n",
    "    nearest = list()\n",
    "    for i in range(56):\n",
    "        temp = list()\n",
    "        for j in range(56):\n",
    "            if i != j:\n",
    "                if dist(coords[i], coords[j]) < r:\n",
    "                    temp.append(j+1)\n",
    "        nearest.append((i+1, tuple(temp)))\n",
    "    return nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = get_nearest(coords,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestamps = np.unique(data[:,0]%10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create intervals to sample over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "intervals=[]\n",
    "for ii in range(0,len(timestamps)-window_size+1,20):\n",
    "    intervals.append(timestamps[ii:ii+window_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to estimate the distribution for each 20 minute interval (maybe less, 5 or 10 minutes might make more sense) for each sensor. \n",
    "\n",
    "From this distribution, you can randomly sample a specified number of times and then take the average of this sample to fill in the missing data. \n",
    "\n",
    "After you've filled the missing data you can then take a spatial average (using the nearest neighbors of each sensor that has missing data at that time step), giving the neighbors a higher weighting. \n",
    "\n",
    "Do this form of median filtering a couple of times. Check and see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1"
     ]
    }
   ],
   "source": [
    "sampled_flow_by_interval = np.zeros((len(intervals),num_sensors))\n",
    "ival_count = 0\n",
    "for intval in intervals:\n",
    "    print ival_count\n",
    "    for i_sens in range(num_sensors):\n",
    "        sensor = data[:, [0, i_sens+1]]\n",
    "        sensor = sensor[sensor[:, 1] > -1]\n",
    "        sensor[:, 0] %= 10000\n",
    "        X = list()\n",
    "        for time in intval:\n",
    "            filtered = sensor[sensor[:, 0] == time]\n",
    "            if filtered.shape[0] != 0:\n",
    "                choice = np.random.choice(np.arange(filtered.shape[0]))\n",
    "\n",
    "                X.append(filtered[:,1])\n",
    "        X = list(itertools.chain.from_iterable(X))\n",
    "        \n",
    "        grid = GridSearchCV(KernelDensity(),\n",
    "                    {'bandwidth': np.logspace(-1, 1, 10)},\n",
    "                    cv=20) # 20-fold cross-validation\n",
    "        grid.fit(np.array(X).reshape(len(X), 1))\n",
    "        kde = grid.best_estimator_\n",
    "        \n",
    "        # Sample from kde and find expected value\n",
    "        sampled_entry = np.abs(np.ceil(np.mean(np.abs(kde.sample(250)))-0.8))\n",
    "        \n",
    "        # Place sampled entry into look-up matrix\n",
    "        sampled_flow_by_interval[ival_count,i_sens] = sampled_entry\n",
    "    ival_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Place interval sampling into missing data locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensor_list = np.linspace(1,56,56)\n",
    "for i in range(data.shape[0]):\n",
    "    temp = data[i,1:]\n",
    "    missing_sensors = sensor_list[temp==-1]\n",
    "    if len(missing_sensors) == 0:\n",
    "        continue\n",
    "\n",
    "    time = data[i,0]%10000\n",
    "    \n",
    "    sample_intervals = []\n",
    "    counter = 0\n",
    "    for intval in intervals:\n",
    "        if time in intval:\n",
    "            sample_intervals.append(counter)\n",
    "        counter += 1\n",
    "        \n",
    "    for i_sens in missing_sensors:\n",
    "        data[i,int(i_sens-1)] = np.mean(sampled_flow_by_interval[sample_intervals,int(i_sens-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take spatial average twice (accounts for neighboring sensors being offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for repeat in range(2):\n",
    "    for i in range(data.shape[0]):\n",
    "        temp = orig_data[i,1:]\n",
    "        missing_sensors = sensor_list[temp==-1]\n",
    "        if len(missing_sensors)==0:\n",
    "            continue\n",
    "        for i_sens in missing_sensors:\n",
    "            neighbors = n[int(i_sens-1)][1]\n",
    "            num_neighbors = len(neighbors)\n",
    "            weighting = float(2*num_neighbors + 1)\n",
    "        \n",
    "            data[i,i_sens] = (2/weighting)*(np.sum(data[i,neighbors])) + data[i,int(i_sens)]/weighting\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query sampled data set and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/test.txt') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    reader.next()\n",
    "    with open ('final_submission.txt', 'w') as f:\n",
    "        counter = 1\n",
    "        f.write('Index,Count\\n')\n",
    "        for row in reader:\n",
    "            f.write('{},{}\\n'.format(counter, query_data(data,int(row[0][1:]),int(row[1]),int(row[2]))))\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
